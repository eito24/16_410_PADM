{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problem Set 03: Adversarial Games\n",
    "\n",
    "\n",
    "0. [Credit for Contributors (required)](#contributors)\n",
    "\n",
    "2. [Adversarial Games](#problem2)\n",
    "    1. [Max-Min (50 points)](#part1)\n",
    "    2. [Max-Min with Alpha-Beta pruning (30 points)](#part2)\n",
    "\n",
    "    \n",
    "**80 points** total for Problem Set 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"contributors\"></a> Credit for Contributors\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this problem set:\n",
    "\n",
    "Ex: I worked with Bob on the cat activity planning problem.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L11_16_410-13_F23_Multiagent_Games_and_AlphaGo.pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to run the cell below to import the code needed for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from utils import *\n",
    "from tests import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"problem2\"></a> Problem 1: The Cut-Throat Game of Tic-Tac-Toe\n",
    "\n",
    "Though the game of tic-tac-toe is very simple, it serves as a good example for MiniMax search and alpha-beta pruning because it is fully solvable. In this problem set, you will implement MiniMax search with and without alpha-beta pruning, and compare performance. You will then simulate a full game to prove that an optimal strategy in tic-tac-toe can only guarantee a tie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined for you a `game_state` class, which works for general games, and a `tic_tac_toe_board` class, both defined in the file `utils.py`. You may want to look in this file now to see the specifics of these classes.\n",
    "\n",
    "A `tic_tac_toe_board` object is defined as follows:\n",
    "\n",
    "```\n",
    "tic_tac_toe_board(symbols)\n",
    "```\n",
    "\n",
    "The `symbols` argument is a list of 9 elements which may be one of `'x'`, `'o'`, or `' '`, corresponding to the symbols on the board supplied row by row.\n",
    "\n",
    "You will not work directly with a `tic_tac_toe_board`. Instead, a `game_state` object will track the board state of any two player game object supplied to it. It will also provide information on the current player, and the state of the game in the last move. You can think of a `game_state` object as a graph node. An instance is defined as:\n",
    "\n",
    "```\n",
    "game_state(board,parent=None)\n",
    "```\n",
    "\n",
    "The `board` arguement is any game board, and the `parent` argument refers to the previous game state. If `None` is supplied as the parent, the game is assumed to have started from this state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the current board, you may use `print game_state` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a game state for tic-tac-toe\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x','x','o','o',' ',' ']))\n",
    "# View the state of the board\n",
    "print(example_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, a `game_state` is initialized assuming player 1, who plays x's and attempts to maximize score, is playing first. Player 2 plays o's and attempts to minimize the score. \n",
    "\n",
    "We attribue a score of +1 to any game state where x (player 1) wins, -1 to any game state where o (player 2) wins, and 0 to any tied or incomplete game state. You may see the score using `game_state.score()`, and check whether a game is complete using `game_state.terminal_check()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "Game complete? False\n",
      "Score of this game is 0: Game incomplete.\n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   | x\n",
      "\n",
      "Game complete? True\n",
      "Score of this game is 1: x wins.\n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | o\n",
      "\n",
      "Game complete? True\n",
      "Score of this game is -1: o wins.\n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | x | o\n",
      "\n",
      "Game complete? True\n",
      "Score of this game is 0: Game tie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see some example games, who has won, and whether the game is complete.\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x','x','o','o',' ',' ']))\n",
    "print(example_state)\n",
    "print('Game complete? {}'.format(example_state.terminal_check()))\n",
    "print('Score of this game is {}: Game incomplete.\\n'.format(example_state.score()))\n",
    "\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x','x','o','o',' ','x']))\n",
    "print(example_state)\n",
    "print('Game complete? {}'.format(example_state.terminal_check()))\n",
    "print('Score of this game is {}: x wins.\\n'.format(example_state.score()))\n",
    "\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x','x','o','o','o','o']))\n",
    "print(example_state)\n",
    "print('Game complete? {}'.format(example_state.terminal_check()))\n",
    "print('Score of this game is {}: o wins.\\n'.format(example_state.score()))\n",
    "\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x','x','o','o','x','o']))\n",
    "print(example_state)\n",
    "print('Game complete? {}'.format(example_state.terminal_check()))\n",
    "print('Score of this game is {}: Game tie.\\n'.format(example_state.score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player who needs to play next in any given `game_state` is given through the command `game_state.player`. The function `game_state.successors()` creates a list of `game_state` objects that could be reachable within a move of the current player. The parent of the successors is automatically allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example state:\n",
      "x | o | x\n",
      "--+---+--\n",
      "x |   | o\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "Next player is 1 and the possible successor states are:\n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x |   | o\n",
      "--+---+--\n",
      "o | x |  \n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x |   | o\n",
      "--+---+--\n",
      "o |   | x\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Example state:\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "Next player is 2 and the possible successor states are:\n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o |  \n",
      "\n",
      "x | o | x\n",
      "--+---+--\n",
      "x | x | o\n",
      "--+---+--\n",
      "o |   | o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see current players and successor states\n",
    "example_state = game_state(tic_tac_toe_board(['x','o','x','x',' ','o','o',' ',' ']))\n",
    "print('Example state:')\n",
    "print(example_state)\n",
    "print('Next player is {} and the possible successor states are:\\n'.format(example_state.player))\n",
    "successor_states = example_state.successors()\n",
    "for s in successor_states:\n",
    "    print(s)\n",
    "    \n",
    "print('-----------------------------------------\\n')\n",
    "example_state = successor_states[0]\n",
    "print('Example state:')\n",
    "print(example_state)\n",
    "print('Next player is {} and the possible successor states are:\\n'.format(example_state.player))\n",
    "successor_states = example_state.successors()\n",
    "for s in successor_states:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"part1\"/> Implement MiniMax Search\n",
    "\n",
    "We will use MiniMax to produce a game where both players are following their optimal strategy. You should be able to convince yourself that in this case, the outcome of the entire game can be defined at the start. \n",
    "\n",
    "You will define the following functions:\n",
    "\n",
    "```python\n",
    "def maximize_score(state)\n",
    "def minimize_score(state)\n",
    "```\n",
    "\n",
    "Both functions take a `game_state` object as input. It is assumed that the when `maximize_score` is run, the next player to play is player 1, while `minimize_score` is run when the next player is player 2.  \n",
    "\n",
    "The output of `maximize_score` will be a tuple `(max_score, states_explored, optimal_play)`, where: \n",
    "\n",
    "- `max_score` is the maximum score that can be achieved starting from the provided state if both players follow an optimum strategy. \n",
    "- `states_explored` is the total number of game states that have been considered to perform this computation (including the current state). If your search reaches the same state multiple times, count it multiple times.\n",
    "- `optimal_play` is a list of `game_state` objects following the optimal game `[state, state2, state3, ..., final_state]` from the current state (leftmost element of list) to its conclusion (rightmost element).\n",
    "\n",
    "Similarly, the output of `minimize_score` will be a tuple `(min_score, states_explored, optimal_play)`, where:\n",
    "\n",
    "- `min_score` is the minimum score that can be achieved starting from the provided state if both players follow an optimum strategy. \n",
    "- `states_explored` and `optimal_play` are defined as above.\n",
    "\n",
    "**In the case where multiple moves give a tie for the optimal play, the `optimal_play` list should follow the first successor in the list generated by `state.successors()`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Implement functions `maximize_score(state)` and `minimize_score(state)` below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6c17fb58ab24f8f13952594caed9f9f",
     "grade": false,
     "grade_id": "minimax_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maximize_score(state):\n",
    "    max_score = -float(\"inf\")\n",
    "    states_explored = 1\n",
    "    optimal_play = [state,]\n",
    "    for successor in state.successors():\n",
    "        if successor.terminal_check():\n",
    "            states_explored += 1\n",
    "            successor.v = successor.score()\n",
    "            if successor.v > max_score:\n",
    "                toadd = [successor,]\n",
    "                max_score = successor.v\n",
    "        else:\n",
    "            result = minimize_score(successor)\n",
    "            successor.v = result[0]\n",
    "            states_explored += result[1]\n",
    "            if successor.v > max_score:\n",
    "                toadd = result[2]\n",
    "                max_score = successor.v\n",
    "    optimal_play = optimal_play + toadd\n",
    "    return (max_score, states_explored, optimal_play)\n",
    "\n",
    "def minimize_score(state):\n",
    "    min_score = float(\"inf\")\n",
    "    states_explored = 1\n",
    "    optimal_play = [state,]\n",
    "    for successor in state.successors():\n",
    "        if successor.terminal_check():\n",
    "            states_explored += 1\n",
    "            successor.v = successor.score()\n",
    "            if successor.v < min_score:\n",
    "                toadd = [successor,]\n",
    "                min_score = successor.v\n",
    "        else:\n",
    "            result = maximize_score(successor)\n",
    "            successor.v = result[0]\n",
    "            states_explored += result[1]\n",
    "            if successor.v < min_score:\n",
    "                toadd = result[2]\n",
    "                min_score = successor.v\n",
    "    optimal_play = optimal_play + toadd\n",
    "    return (min_score, states_explored, optimal_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f07deea0e1f56ec0f9e4a12d5ab76bda",
     "grade": true,
     "grade_id": "minimax",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x | o |  \n",
      "--+---+--\n",
      "x |   |  \n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "x | o |  \n",
      "--+---+--\n",
      "x | x |  \n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "x | o | o\n",
      "--+---+--\n",
      "x | x |  \n",
      "--+---+--\n",
      "o |   |  \n",
      "\n",
      "x | o | o\n",
      "--+---+--\n",
      "x | x | x\n",
      "--+---+--\n",
      "o |   |  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-success\">\n",
       "        <strong>Test passed!!</strong>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Test your minimax search code here.\"\"\"\n",
    "test_minimax(maximize_score,minimize_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"part2\"/> Implement Alpha-Beta Pruning\n",
    "\n",
    "Now you will implement alpha-beta pruning into your minimax functions, and demonstrate that the same result is achieved with fewer game states needing to be searched. \n",
    "\n",
    "You will define the following functions:\n",
    "\n",
    "```python\n",
    "def maximize_score_alpha_beta(state,alpha,beta)\n",
    "def minimize_score_alpha_beta(state,alpha,beta)\n",
    "```\n",
    "\n",
    "These functions will look very similar to your implementations of `maximize_score` and `minimize_score` (in fact, a good place to start is by copying and pasting your code from above), except they will take the alpha and beta parameters defined by alpha-beta pruning. The output format should be the same as the corresponding functions without pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Implement functions `maximize_score_alpha_beta(state,alpha,beta)` and `minimize_score_alpha_beta(state,alpha,beta)` below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f0f0999884c0df443ba0cb18fda91ca",
     "grade": false,
     "grade_id": "alpha_beta_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code for minimax search with alpha-beta pruning here.\n",
    "\n",
    "def maximize_score_alpha_beta(state,alpha,beta):\n",
    "\n",
    "    if state.player != 1:\n",
    "        raise Error\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if state.terminal_check():\n",
    "        return (state.score(),1,[state,])\n",
    "    \n",
    "    states_explored = 1\n",
    "    optimal_play = [state,]\n",
    "    max_score = -float(\"inf\")\n",
    "    \n",
    "    for successor in state.successors():\n",
    "        \"\"\"\n",
    "        if successor.terminal_check():\n",
    "            states_explored += 1\n",
    "            successor.v = successor.score()\n",
    "            if successor.v > max_score:\n",
    "                toadd = [successor,]\n",
    "                max_score = successor.v\n",
    "                if max_score >= beta:\n",
    "                    optimal_play = optimal_play + toadd\n",
    "                    return (max_score, states_explored,optimal_play)\n",
    "        else:\n",
    "        \"\"\"\n",
    "        result = minimize_score_alpha_beta(successor,alpha,beta)\n",
    "        successor.v = result[0]\n",
    "        states_explored += result[1]\n",
    "        if successor.v > max_score:\n",
    "            toadd = result[2]\n",
    "            max_score = successor.v\n",
    "            alpha = max(alpha,max_score)\n",
    "            if max_score >= beta:\n",
    "                optimal_play = optimal_play + toadd\n",
    "                return (max_score, states_explored,optimal_play)\n",
    "    optimal_play = optimal_play + toadd\n",
    "    alpha = max(alpha,max_score)\n",
    "    return (max_score, states_explored, optimal_play)\n",
    "    \n",
    "\n",
    "def minimize_score_alpha_beta(state,alpha,beta):\n",
    "\n",
    "    if state.player != 2:\n",
    "        raise Error\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if state.terminal_check():\n",
    "        return (state.score(),1,[state,])\n",
    "    \n",
    "    states_explored = 1\n",
    "    optimal_play = [state,]\n",
    "    min_score = float(\"inf\")\n",
    "    \n",
    "    for successor in state.successors():\n",
    "        \"\"\"\n",
    "        if successor.terminal_check():\n",
    "            states_explored += 1\n",
    "            successor.v = successor.score()\n",
    "            if successor.v < min_score:\n",
    "                toadd = [successor,]\n",
    "                min_score = successor.v\n",
    "                if min_score <= alpha:\n",
    "                    optimal_play = optimal_play + toadd\n",
    "                    return (min_score, states_explored,optimal_play)\n",
    "        else:\n",
    "        \"\"\"\n",
    "        result = maximize_score_alpha_beta(successor,alpha,beta)\n",
    "        successor.v = result[0]\n",
    "        states_explored += result[1]\n",
    "        if successor.v < min_score:\n",
    "            toadd = result[2]\n",
    "            min_score = successor.v\n",
    "            beta = min(beta,min_score)\n",
    "            if min_score <= alpha:\n",
    "                optimal_play = optimal_play + toadd\n",
    "                return (min_score, states_explored,optimal_play)\n",
    "    optimal_play = optimal_play + toadd\n",
    "    beta = min(beta,min_score)\n",
    "    return (min_score, states_explored, optimal_play)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "881dfc7444e52488028985244c08efa0",
     "grade": true,
     "grade_id": "alpha_beta",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-success\">\n",
       "        <strong>Test passed!!</strong>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Test your alpha beta search code here.\"\"\"\n",
    "test_alpha_beta(maximize_score_alpha_beta,minimize_score_alpha_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a Full Game\n",
    "\n",
    "You're now prepared to run a full game of tic-tac-toe from an initially blank state. If it was possible to always guarantee a win against a perfect opponent, you would see x's win the game. Unfortunately, this isn't possible! Let's see this by running your code boht with and without alpha-beta pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score = 0\n",
      "States explored = 549946\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x |   |  \n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x |  \n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o |  \n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x | o |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x | o | x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see an optimum game of tic-tac-toe. Note the performance without alpha-beta pruning. This may\n",
    "# take a few tens of seconds. \n",
    "blank_game = game_state(tic_tac_toe_board([' ',' ',' ',' ',' ',' ',' ',' ',' ']))\n",
    "(max_score, states_explored, optimal_play) = maximize_score(blank_game)\n",
    "print('Max score = {}'.format(max_score))\n",
    "print('States explored = {}'.format(states_explored))\n",
    "for s in optimal_play:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score = 0\n",
      "States explored = 18297\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x |   |  \n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x |  \n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "  | o |  \n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o |  \n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x |   |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x | o |  \n",
      "\n",
      "x | x | o\n",
      "--+---+--\n",
      "o | o | x\n",
      "--+---+--\n",
      "x | o | x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see an optimum game of tic-tac-toe. Note the performance gain with alpha-beta pruning.  \n",
    "blank_game = game_state(tic_tac_toe_board([' ',' ',' ',' ',' ',' ',' ',' ',' ']))\n",
    "(max_score, states_explored, optimal_play) = maximize_score_alpha_beta(blank_game,-2,2)\n",
    "print('Max score = {}'.format(max_score))\n",
    "print('States explored = {}'.format(states_explored))\n",
    "for s in optimal_play:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
